# GeminiAI to OpenAI API Adapter

---
[ä¸­æ–‡](#-ä¸­æ–‡) | [English](#-english)
---

## ğŸ‡¨ğŸ‡³ ä¸­æ–‡

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªè½»é‡çº§çš„ Go åº”ç”¨ï¼Œå…¶åŠŸèƒ½æ˜¯å°† OpenAI èŠå¤© API æ ¼å¼çš„è¯·æ±‚è½¬æ¢ä¸º Google Gemini API æ ¼å¼ã€‚å®ƒå…è®¸æ‚¨ä½¿ç”¨å…¼å®¹ OpenAI çš„å®¢æˆ·ç«¯æ¥è°ƒç”¨ Gemini åç«¯ï¼ŒåŒ…æ‹¬ç¬¬ä¸‰æ–¹çš„ Gemini æœåŠ¡æä¾›å•†ã€‚

### âœ¨ åŠŸèƒ½ç‰¹æ€§

-   å°† OpenAI `/v1/chat/completions` è¯·æ±‚è½¬æ¢ä¸º Gemini API æ ¼å¼ã€‚
-   å°† Gemini API çš„å“åº”è½¬æ¢å› OpenAI æ ¼å¼ã€‚
-   é€šè¿‡ `config.yaml` æ–‡ä»¶è¿›è¡Œçµæ´»é…ç½®ã€‚
-   é€šè¿‡ `.gitignore` ä¿æŠ¤æ‚¨çš„æ•æ„Ÿé…ç½®ä¿¡æ¯ã€‚
-   **è¯·æ±‚æ—¥å¿—**ï¼šå¯å°†æ¯ä¸ªè¯·æ±‚çš„è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…æ‹¬IPã€è¯·æ±‚ä½“ã€å“åº”ä½“ç­‰ï¼‰è®°å½•åˆ°æœ¬åœ°JSON Linesæ–‡ä»¶ä¸­ã€‚
-   æ”¯æŒå¯é€‰çš„ Bearer Token è®¤è¯ã€‚
-   åŸºäº Go çš„é«˜æ€§èƒ½åç«¯ï¼Œä¸ºé«˜å¹¶å‘åœºæ™¯è®¾è®¡ã€‚
-   æä¾› `Dockerfile`ï¼Œä¾¿äºå®¹å™¨åŒ–éƒ¨ç½²ã€‚

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### ç¯å¢ƒè¦æ±‚

-   Go 1.22 æˆ–æ›´é«˜ç‰ˆæœ¬
-   Docker (å¦‚æœéœ€è¦å®¹å™¨åŒ–éƒ¨ç½²)

#### âš™ï¸ é…ç½®

1.  **å¤åˆ¶é…ç½®æ–‡ä»¶æ¨¡æ¿**:
    -   å°† `config.yaml.example` å¤åˆ¶ä¸º `config.yaml`ã€‚
    -   `.gitignore` æ–‡ä»¶å·²é…ç½®å¥½ï¼Œä¼šå¿½ç•¥ `config.yaml`ï¼Œé¿å…æ‚¨çš„å¯†é’¥è¢«æ„å¤–æäº¤ã€‚
2.  **ç¼–è¾‘ `config.yaml`**:
    ```yaml
    server:
      port: 8080

    log:
      # æ˜¯å¦å¯ç”¨è¯·æ±‚æ—¥å¿—è®°å½•
      enabled: true
      # æ—¥å¿—æ–‡ä»¶è·¯å¾„
      path: "requests.log"

    gemini:
      # ä½ çš„ç¬¬ä¸‰æ–¹Gemini APIåŸºç¡€URL
      base_url: "your genai base_url" 
      # ä½ çš„ç¬¬ä¸‰æ–¹Gemini APIå¯†é’¥
      api_key: "your api key"

    auth:
      # ç”¨äºä¿æŠ¤æ­¤ä»£ç†æœåŠ¡çš„APIå¯†é’¥ï¼Œå®¢æˆ·ç«¯éœ€è¦åœ¨Authorizationå¤´ä¸­æä¾›
      # ç•™ç©º ("") è¡¨ç¤ºç¦ç”¨è®¤è¯
      openai_api_key: "your openai compatible api key"
    ```

#### ğŸ’» æœ¬åœ°è¿è¡Œ (Linux / macOS)

1.  å®‰è£…ä¾èµ–:
    ```bash
    go mod tidy
    ```
2.  è¿è¡Œåº”ç”¨:
    ```bash
    go run main.go
    ```
    æœåŠ¡å°†å¯åŠ¨åœ¨ `config.yaml` ä¸­æŒ‡å®šçš„ç«¯å£ä¸Šã€‚

#### ğŸ’» æœ¬åœ°è¿è¡Œ (Windows)

1.  **å®‰è£… Go**:
    -   è®¿é—® [Go å®˜æ–¹ä¸‹è½½é¡µé¢](https://golang.org/dl/) ä¸‹è½½å¹¶å®‰è£…é€‚ç”¨äº Windows çš„ Goã€‚
    -   å®‰è£…è¿‡ç¨‹ä¸­ï¼Œè¯·ç¡®ä¿å‹¾é€‰ "Add Go to your PATH" é€‰é¡¹ã€‚
2.  **æ‰“å¼€ç»ˆç«¯**:
    -   ä½ å¯ä»¥ä½¿ç”¨ `CMD` æˆ–è€… `PowerShell`ã€‚
3.  **ä¸‹è½½é¡¹ç›®ä»£ç **:
    -   å¦‚æœä½ å®‰è£…äº† Gitï¼Œå¯ä»¥ä½¿ç”¨ `git clone`ã€‚
    -   æˆ–è€…ï¼Œç›´æ¥ä¸‹è½½é¡¹ç›®çš„ ZIP å‹ç¼©åŒ…å¹¶è§£å‹ã€‚
4.  **ç¼–è¯‘å¹¶è¿è¡Œ**:
    -   åœ¨é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹ï¼Œæ‰“å¼€ç»ˆç«¯å¹¶è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥ç¼–è¯‘ä¸€ä¸ª `.exe` å¯æ‰§è¡Œæ–‡ä»¶ï¼š
      ```powershell
      go build -o gemini2openai.exe .
      ```
    -   ç¼–è¯‘æˆåŠŸåï¼Œç›´æ¥è¿è¡Œè¯¥ç¨‹åºï¼š
      ```powershell
      .\gemini2openai.exe
      ```
    æœåŠ¡å°†å¯åŠ¨åœ¨ `config.yaml` ä¸­æŒ‡å®šçš„ç«¯å£ä¸Šã€‚

#### ğŸ³ ä½¿ç”¨ Docker è¿è¡Œ

1.  æ„å»º Docker é•œåƒ:
    ```bash
    docker build -t gemini2openai .
    ```
2.  è¿è¡Œ Docker å®¹å™¨:
    ```bash
    # Linux / macOS
    docker run -p 8080:8080 -v $(pwd)/config.yaml:/root/config.yaml gemini2openai

    # Windows (CMD)
    docker run -p 8080:8080 -v "%cd%\config.yaml:/root/config.yaml" gemini2openai
    ```
    æ­¤å‘½ä»¤ä¼šå°†ä¸»æœºçš„ 8080 ç«¯å£æ˜ å°„åˆ°å®¹å™¨çš„ 8080 ç«¯å£ï¼Œå¹¶å°†æœ¬åœ°çš„ `config.yaml` æŒ‚è½½åˆ°å®¹å™¨ä¸­ã€‚

### ğŸ”Œ API è°ƒç”¨ç¤ºä¾‹

å‘ `http://localhost:8080/v1/chat/completions` å‘é€ä¸€ä¸ªæ ‡å‡†çš„ OpenAI èŠå¤© API æ ¼å¼çš„ POST è¯·æ±‚ã€‚

**ä½¿ç”¨ cURL çš„ç¤ºä¾‹:**

```bash
curl http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer you_api_key" \
  -d '{
    "model": "gemini-2.5-flash",
    "messages": [
      {
        "role": "user",
        "content": "ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿ"
      }
    ]
  }'
```

---

## ğŸ‡¬ğŸ‡§ English

This project is a lightweight Go application that acts as an adapter to convert API requests from the OpenAI Chat Completions format to the Google Gemini format. It allows you to use OpenAI-compatible clients with a Gemini backend, including third-party Gemini providers.

### âœ¨ Features

-   Converts OpenAI `/v1/chat/completions` requests to Gemini API format.
-   Converts Gemini API responses back to OpenAI format.
-   Flexible configuration via a `config.yaml` file.
-   Protects your sensitive configuration with `.gitignore`.
-   **Request Logging**: Can log detailed information for each request (IP, request body, response body, etc.) to a local JSON Lines file.
-   Supports optional Bearer Token authentication.
-   High-performance Go backend, designed for concurrent requests.
-   Provides a `Dockerfile` for easy containerization.

### ğŸš€ Getting Started

#### Prerequisites

-   Go 1.22 or later
-   Docker (for containerized deployment)

#### âš™ï¸ Configuration

1.  **Copy the config template**:
    -   Copy `config.yaml.example` to `config.yaml`.
    -   The `.gitignore` file is already configured to ignore `config.yaml`, preventing your keys from being accidentally committed.
2.  **Edit `config.yaml`**:
    ```yaml
    server:
      port: 8080

    log:
      # Enable or disable request logging
      enabled: true
      # Path to the log file
      path: "requests.log"

    gemini:
      # Your third-party Gemini API base URL
      base_url: "your genai base_url" 
      # Your third-party Gemini API key
      api_key: "your api key"

    auth:
      # API key to protect this proxy service. Clients must provide it in the Authorization header.
      # Leave it empty ("") to disable authentication.
      openai_api_key: "your openai compatible api key"
    ```

#### ğŸ’» Running Locally (Linux / macOS)

1.  Install dependencies:
    ```bash
    go mod tidy
    ```
2.  Run the application:
    ```bash
    go run main.go
    ```
    The server will start on the port specified in your `config.yaml`.

#### ğŸ’» Running Locally (Windows)

1.  **Install Go**:
    -   Visit the [official Go downloads page](https://golang.org/dl/) to download and install Go for Windows.
    -   During installation, ensure the "Add Go to your PATH" option is checked.
2.  **Open a terminal**:
    -   You can use `CMD` or `PowerShell`.
3.  **Get the project code**:
    -   If you have Git, use `git clone`.
    -   Alternatively, download the project as a ZIP file and extract it.
4.  **Build and run**:
    -   In the project's root directory, open a terminal and run the following command to build an `.exe` executable:
      ```powershell
      go build -o gemini2openai.exe .
      ```
    -   Once built, run the program:
      ```powershell
      .\gemini2openai.exe
      ```
    The server will start on the port specified in `config.yaml`.

#### ğŸ³ Running with Docker

1.  Build the Docker image:
    ```bash
    docker build -t gemini2openai .
    ```
2.  Run the Docker container:
    ```bash
    # Linux / macOS
    docker run -p 8080:8080 -v $(pwd)/config.yaml:/root/config.yaml gemini2openai

    # Windows (CMD)
    docker run -p 8080:8080 -v "%cd%\config.yaml:/root/config.yaml" gemini2openai
    ```
    This command maps port 8080 on your host to port 8080 in the container and mounts your local `config.yaml` into it.

### ğŸ”Œ API Usage Example

Send a standard OpenAI Chat Completions POST request to `http://localhost:8080/v1/chat/completions`.

**Example with cURL:**

```bash
curl http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer you_api_key" \
  -d '{
    "model": "gemini-2.5-flash",
    "messages": [
      {
        "role": "user",
        "content": "Hello, who are you?"
      }
    ]
  }'